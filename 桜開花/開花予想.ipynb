{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "kaika_data_set = pd.read_csv('./桜開花.csv',header=0,engine='python')\n",
    "\n",
    "\n",
    "\n",
    "X = DataFrame(kaika_data_set.drop('開花日',axis=1))\n",
    "y = DataFrame(kaika_data_set['開花日'])\n",
    "\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.1,random_state=0)\n",
    "kaika_data_set['開花日'].unique().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 5,351\n",
      "Trainable params: 5,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3063 samples, validate on 341 samples\n",
      "Epoch 1/100\n",
      "3063/3063 [==============================] - 1s 470us/step - loss: 89.0963 - acc: 0.0385 - val_loss: 67.4841 - val_acc: 0.0235\n",
      "Epoch 2/100\n",
      "3063/3063 [==============================] - 0s 141us/step - loss: 69.4770 - acc: 0.0395 - val_loss: 68.7557 - val_acc: 0.0381\n",
      "Epoch 3/100\n",
      "3063/3063 [==============================] - 0s 97us/step - loss: 69.4028 - acc: 0.0441 - val_loss: 67.4936 - val_acc: 0.0469\n",
      "Epoch 4/100\n",
      "3063/3063 [==============================] - ETA: 0s - loss: 68.4095 - acc: 0.0463e+ - ETA: 0s - loss: 67.2393 - a - 0s 131us/step - loss: 69.0368 - acc: 0.0457 - val_loss: 65.9298 - val_acc: 0.0352\n",
      "Epoch 5/100\n",
      "3063/3063 [==============================] - 0s 117us/step - loss: 68.9674 - acc: 0.0470 - val_loss: 66.2132 - val_acc: 0.0469\n",
      "Epoch 6/100\n",
      "3063/3063 [==============================] - 0s 96us/step - loss: 68.6317 - acc: 0.0480 - val_loss: 68.2980 - val_acc: 0.0411\n",
      "Epoch 7/100\n",
      "3063/3063 [==============================] - 0s 133us/step - loss: 69.2832 - acc: 0.0428 - val_loss: 65.8697 - val_acc: 0.0381\n",
      "Epoch 8/100\n",
      "3063/3063 [==============================] - 0s 119us/step - loss: 68.5256 - acc: 0.0496 - val_loss: 65.6014 - val_acc: 0.0352\n",
      "Epoch 9/100\n",
      "3063/3063 [==============================] - 0s 109us/step - loss: 68.7407 - acc: 0.0500 - val_loss: 65.9351 - val_acc: 0.0528\n",
      "Epoch 10/100\n",
      "3063/3063 [==============================] - 0s 135us/step - loss: 67.9259 - acc: 0.0451 - val_loss: 65.5457 - val_acc: 0.0440\n",
      "Epoch 11/100\n",
      "3063/3063 [==============================] - 0s 106us/step - loss: 68.3613 - acc: 0.0490 - val_loss: 65.9342 - val_acc: 0.0528\n",
      "Epoch 12/100\n",
      "3063/3063 [==============================] - 0s 104us/step - loss: 68.0124 - acc: 0.0451 - val_loss: 66.5236 - val_acc: 0.0469\n",
      "Epoch 13/100\n",
      "3063/3063 [==============================] - 0s 117us/step - loss: 68.5401 - acc: 0.0535 - val_loss: 65.3338 - val_acc: 0.0411\n",
      "Epoch 14/100\n",
      "3063/3063 [==============================] - 0s 97us/step - loss: 68.0333 - acc: 0.0513 - val_loss: 67.0821 - val_acc: 0.0323\n",
      "Epoch 15/100\n",
      "3063/3063 [==============================] - 0s 118us/step - loss: 67.8633 - acc: 0.0444 - val_loss: 65.0138 - val_acc: 0.0499\n",
      "Epoch 16/100\n",
      "3063/3063 [==============================] - 0s 94us/step - loss: 67.9210 - acc: 0.0486 - val_loss: 64.6622 - val_acc: 0.0323\n",
      "Epoch 17/100\n",
      "3063/3063 [==============================] - 0s 86us/step - loss: 68.0756 - acc: 0.0457 - val_loss: 65.4331 - val_acc: 0.0381\n",
      "Epoch 18/100\n",
      "3063/3063 [==============================] - 0s 79us/step - loss: 67.6425 - acc: 0.0451 - val_loss: 64.5741 - val_acc: 0.0440\n",
      "Epoch 19/100\n",
      "3063/3063 [==============================] - 0s 158us/step - loss: 67.4699 - acc: 0.0516 - val_loss: 64.7280 - val_acc: 0.0499\n",
      "Epoch 20/100\n",
      "3063/3063 [==============================] - 0s 126us/step - loss: 67.2674 - acc: 0.0496 - val_loss: 64.2460 - val_acc: 0.0352\n",
      "Epoch 21/100\n",
      "3063/3063 [==============================] - 0s 118us/step - loss: 67.3858 - acc: 0.0519 - val_loss: 64.1374 - val_acc: 0.0440\n",
      "Epoch 22/100\n",
      "3063/3063 [==============================] - 0s 121us/step - loss: 67.0860 - acc: 0.0535 - val_loss: 65.1693 - val_acc: 0.0381\n",
      "Epoch 23/100\n",
      "3063/3063 [==============================] - 0s 117us/step - loss: 67.2997 - acc: 0.0480 - val_loss: 67.9843 - val_acc: 0.0411\n",
      "Epoch 24/100\n",
      "3063/3063 [==============================] - 0s 94us/step - loss: 67.1941 - acc: 0.0503 - val_loss: 65.4261 - val_acc: 0.0381\n",
      "Epoch 25/100\n",
      "3063/3063 [==============================] - 0s 112us/step - loss: 67.4127 - acc: 0.0454 - val_loss: 63.9989 - val_acc: 0.0440\n",
      "Epoch 26/100\n",
      "3063/3063 [==============================] - 0s 83us/step - loss: 66.8678 - acc: 0.0516 - val_loss: 65.5150 - val_acc: 0.0411\n",
      "Epoch 27/100\n",
      "3063/3063 [==============================] - 0s 84us/step - loss: 66.9424 - acc: 0.0470 - val_loss: 65.1319 - val_acc: 0.0411\n",
      "Epoch 28/100\n",
      "3063/3063 [==============================] - 0s 79us/step - loss: 67.4464 - acc: 0.0548 - val_loss: 63.8249 - val_acc: 0.0469\n",
      "Epoch 29/100\n",
      "3063/3063 [==============================] - 0s 119us/step - loss: 67.1120 - acc: 0.0500 - val_loss: 63.7278 - val_acc: 0.0381\n",
      "Epoch 30/100\n",
      "3063/3063 [==============================] - 0s 138us/step - loss: 66.8480 - acc: 0.0584 - val_loss: 65.5189 - val_acc: 0.0381\n",
      "Epoch 31/100\n",
      "3063/3063 [==============================] - 0s 113us/step - loss: 66.5919 - acc: 0.0509 - val_loss: 63.5102 - val_acc: 0.0440\n",
      "Epoch 32/100\n",
      "3063/3063 [==============================] - 0s 137us/step - loss: 66.4707 - acc: 0.0539 - val_loss: 63.9572 - val_acc: 0.0469\n",
      "Epoch 33/100\n",
      "3063/3063 [==============================] - 0s 90us/step - loss: 66.2219 - acc: 0.0493 - val_loss: 64.3921 - val_acc: 0.0499\n",
      "Epoch 34/100\n",
      "3063/3063 [==============================] - 0s 80us/step - loss: 66.4088 - acc: 0.0493 - val_loss: 63.0415 - val_acc: 0.0469\n",
      "Epoch 35/100\n",
      "3063/3063 [==============================] - 0s 80us/step - loss: 66.2812 - acc: 0.0526 - val_loss: 63.6649 - val_acc: 0.0469\n",
      "Epoch 36/100\n",
      "3063/3063 [==============================] - 0s 70us/step - loss: 66.0094 - acc: 0.0519 - val_loss: 62.9876 - val_acc: 0.0352\n",
      "Epoch 37/100\n",
      "3063/3063 [==============================] - 0s 71us/step - loss: 66.8351 - acc: 0.0552 - val_loss: 62.8040 - val_acc: 0.0411\n",
      "Epoch 38/100\n",
      "3063/3063 [==============================] - 0s 75us/step - loss: 66.6429 - acc: 0.0542 - val_loss: 65.0712 - val_acc: 0.0469\n",
      "Epoch 39/100\n",
      "3063/3063 [==============================] - 0s 73us/step - loss: 66.1213 - acc: 0.0503 - val_loss: 62.5713 - val_acc: 0.0411\n",
      "Epoch 40/100\n",
      "3063/3063 [==============================] - 0s 76us/step - loss: 66.1732 - acc: 0.0581 - val_loss: 62.4228 - val_acc: 0.0499\n",
      "Epoch 41/100\n",
      "3063/3063 [==============================] - 0s 72us/step - loss: 66.0078 - acc: 0.0591 - val_loss: 62.2413 - val_acc: 0.0440\n",
      "Epoch 42/100\n",
      "3063/3063 [==============================] - 0s 71us/step - loss: 66.0699 - acc: 0.0558 - val_loss: 62.3468 - val_acc: 0.0440\n",
      "Epoch 43/100\n",
      "3063/3063 [==============================] - 0s 72us/step - loss: 65.7492 - acc: 0.0565 - val_loss: 62.1135 - val_acc: 0.0411\n",
      "Epoch 44/100\n",
      "3063/3063 [==============================] - 0s 77us/step - loss: 65.8906 - acc: 0.0535 - val_loss: 62.4501 - val_acc: 0.0323\n",
      "Epoch 45/100\n",
      "3063/3063 [==============================] - 0s 80us/step - loss: 66.2026 - acc: 0.0522 - val_loss: 62.4348 - val_acc: 0.0352\n",
      "Epoch 46/100\n",
      "3063/3063 [==============================] - 0s 78us/step - loss: 65.7449 - acc: 0.0509 - val_loss: 62.1913 - val_acc: 0.0381\n",
      "Epoch 47/100\n",
      "3063/3063 [==============================] - 0s 73us/step - loss: 65.9524 - acc: 0.0542 - val_loss: 63.9870 - val_acc: 0.0645\n",
      "Epoch 48/100\n",
      "3063/3063 [==============================] - 0s 75us/step - loss: 65.5528 - acc: 0.0588 - val_loss: 62.0574 - val_acc: 0.0381\n",
      "Epoch 49/100\n",
      "3063/3063 [==============================] - 0s 70us/step - loss: 65.7203 - acc: 0.0526 - val_loss: 61.8926 - val_acc: 0.0352\n",
      "Epoch 50/100\n",
      "3063/3063 [==============================] - 0s 72us/step - loss: 66.2661 - acc: 0.0535 - val_loss: 62.5480 - val_acc: 0.0499\n",
      "Epoch 51/100\n",
      "3063/3063 [==============================] - 0s 76us/step - loss: 65.7167 - acc: 0.0578 - val_loss: 63.5712 - val_acc: 0.0674\n",
      "Epoch 52/100\n",
      "3063/3063 [==============================] - 0s 73us/step - loss: 65.5563 - acc: 0.0535 - val_loss: 62.8423 - val_acc: 0.0469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "3063/3063 [==============================] - 0s 70us/step - loss: 65.4157 - acc: 0.0519 - val_loss: 61.6389 - val_acc: 0.0264\n",
      "Epoch 54/100\n",
      "3063/3063 [==============================] - 0s 67us/step - loss: 65.3664 - acc: 0.0627 - val_loss: 63.4028 - val_acc: 0.0616\n",
      "Epoch 55/100\n",
      "3063/3063 [==============================] - 0s 83us/step - loss: 65.2556 - acc: 0.0581 - val_loss: 62.6182 - val_acc: 0.0499\n",
      "Epoch 56/100\n",
      "3063/3063 [==============================] - 0s 75us/step - loss: 65.1932 - acc: 0.0565 - val_loss: 62.1468 - val_acc: 0.0469\n",
      "Epoch 57/100\n",
      "3063/3063 [==============================] - 0s 82us/step - loss: 65.6420 - acc: 0.0532 - val_loss: 62.8571 - val_acc: 0.0587\n",
      "Epoch 58/100\n",
      "3063/3063 [==============================] - ETA: 0s - loss: 65.2188 - acc: 0.06 - 0s 97us/step - loss: 65.3595 - acc: 0.0637 - val_loss: 61.4389 - val_acc: 0.0411\n",
      "Epoch 59/100\n",
      "3063/3063 [==============================] - 0s 103us/step - loss: 64.8523 - acc: 0.0620 - val_loss: 61.6605 - val_acc: 0.0440\n",
      "Epoch 60/100\n",
      "3063/3063 [==============================] - 0s 87us/step - loss: 65.5367 - acc: 0.0545 - val_loss: 61.4415 - val_acc: 0.0381\n",
      "Epoch 61/100\n",
      "3063/3063 [==============================] - 0s 81us/step - loss: 65.3512 - acc: 0.0513 - val_loss: 62.0862 - val_acc: 0.0381\n",
      "Epoch 62/100\n",
      "3063/3063 [==============================] - 0s 138us/step - loss: 64.8747 - acc: 0.0604 - val_loss: 62.1333 - val_acc: 0.0235\n",
      "Epoch 63/100\n",
      "3063/3063 [==============================] - 0s 109us/step - loss: 65.0612 - acc: 0.0562 - val_loss: 61.1749 - val_acc: 0.0469\n",
      "Epoch 64/100\n",
      "3063/3063 [==============================] - 0s 90us/step - loss: 65.0946 - acc: 0.0676 - val_loss: 61.5035 - val_acc: 0.0411\n",
      "Epoch 65/100\n",
      "3063/3063 [==============================] - 0s 81us/step - loss: 64.9779 - acc: 0.0548 - val_loss: 62.0772 - val_acc: 0.0411\n",
      "Epoch 66/100\n",
      "3063/3063 [==============================] - 0s 97us/step - loss: 64.8844 - acc: 0.0630 - val_loss: 63.7760 - val_acc: 0.0704\n",
      "Epoch 67/100\n",
      "3063/3063 [==============================] - 0s 116us/step - loss: 65.3504 - acc: 0.0614 - val_loss: 61.9155 - val_acc: 0.0323\n",
      "Epoch 68/100\n",
      "3063/3063 [==============================] - 0s 107us/step - loss: 64.8556 - acc: 0.0594 - val_loss: 61.1729 - val_acc: 0.0411\n",
      "Epoch 69/100\n",
      "3063/3063 [==============================] - 0s 83us/step - loss: 64.8771 - acc: 0.0584 - val_loss: 61.7283 - val_acc: 0.0411\n",
      "Epoch 70/100\n",
      "3063/3063 [==============================] - 0s 96us/step - loss: 65.2457 - acc: 0.0575 - val_loss: 61.1502 - val_acc: 0.0499\n",
      "Epoch 71/100\n",
      "3063/3063 [==============================] - 0s 115us/step - loss: 64.9852 - acc: 0.0607 - val_loss: 61.2037 - val_acc: 0.0499\n",
      "Epoch 72/100\n",
      "3063/3063 [==============================] - 0s 87us/step - loss: 64.8004 - acc: 0.0584 - val_loss: 61.1990 - val_acc: 0.0411\n",
      "Epoch 73/100\n",
      "3063/3063 [==============================] - 0s 111us/step - loss: 65.1645 - acc: 0.0562 - val_loss: 62.7672 - val_acc: 0.0440\n",
      "Epoch 74/100\n",
      "3063/3063 [==============================] - 0s 90us/step - loss: 64.6663 - acc: 0.0548 - val_loss: 64.0659 - val_acc: 0.0587\n",
      "Epoch 75/100\n",
      "3063/3063 [==============================] - 0s 83us/step - loss: 65.0728 - acc: 0.0591 - val_loss: 62.9390 - val_acc: 0.0733\n",
      "Epoch 76/100\n",
      "3063/3063 [==============================] - 0s 84us/step - loss: 64.8849 - acc: 0.0588 - val_loss: 62.3008 - val_acc: 0.0323\n",
      "Epoch 77/100\n",
      "3063/3063 [==============================] - 0s 85us/step - loss: 65.4580 - acc: 0.0539 - val_loss: 61.6686 - val_acc: 0.0469\n",
      "Epoch 78/100\n",
      "3063/3063 [==============================] - 0s 94us/step - loss: 64.9556 - acc: 0.0584 - val_loss: 61.0884 - val_acc: 0.0440\n",
      "Epoch 79/100\n",
      "3063/3063 [==============================] - 0s 147us/step - loss: 64.7959 - acc: 0.0601 - val_loss: 62.4132 - val_acc: 0.0440\n",
      "Epoch 80/100\n",
      "3063/3063 [==============================] - 0s 134us/step - loss: 65.1181 - acc: 0.0630 - val_loss: 61.4282 - val_acc: 0.0469\n",
      "Epoch 81/100\n",
      "3063/3063 [==============================] - 0s 123us/step - loss: 64.6847 - acc: 0.0624 - val_loss: 62.8723 - val_acc: 0.0616\n",
      "Epoch 82/100\n",
      "3063/3063 [==============================] - 0s 95us/step - loss: 65.4108 - acc: 0.0562 - val_loss: 65.7996 - val_acc: 0.0499\n",
      "Epoch 83/100\n",
      "3063/3063 [==============================] - 0s 91us/step - loss: 64.9856 - acc: 0.0529 - val_loss: 61.4056 - val_acc: 0.0381\n",
      "Epoch 84/100\n",
      "3063/3063 [==============================] - 0s 81us/step - loss: 64.8789 - acc: 0.0630 - val_loss: 61.2516 - val_acc: 0.0411\n",
      "Epoch 85/100\n",
      "3063/3063 [==============================] - 0s 136us/step - loss: 64.7464 - acc: 0.0637 - val_loss: 60.8998 - val_acc: 0.0469\n",
      "Epoch 86/100\n",
      "3063/3063 [==============================] - 0s 102us/step - loss: 64.8192 - acc: 0.0575 - val_loss: 61.4697 - val_acc: 0.0352\n",
      "Epoch 87/100\n",
      "3063/3063 [==============================] - 0s 80us/step - loss: 64.9227 - acc: 0.0604 - val_loss: 61.0728 - val_acc: 0.0469\n",
      "Epoch 88/100\n",
      "3063/3063 [==============================] - 0s 86us/step - loss: 65.3705 - acc: 0.0630 - val_loss: 61.3228 - val_acc: 0.0440\n",
      "Epoch 89/100\n",
      "3063/3063 [==============================] - 0s 85us/step - loss: 65.0459 - acc: 0.0607 - val_loss: 61.0653 - val_acc: 0.0440\n",
      "Epoch 90/100\n",
      "3063/3063 [==============================] - 0s 80us/step - loss: 64.5981 - acc: 0.0516 - val_loss: 64.2550 - val_acc: 0.0674\n",
      "Epoch 91/100\n",
      "3063/3063 [==============================] - 0s 79us/step - loss: 64.6573 - acc: 0.0565 - val_loss: 62.8217 - val_acc: 0.0704\n",
      "Epoch 92/100\n",
      "3063/3063 [==============================] - 0s 90us/step - loss: 64.8082 - acc: 0.0535 - val_loss: 61.3138 - val_acc: 0.0528\n",
      "Epoch 93/100\n",
      "3063/3063 [==============================] - 0s 91us/step - loss: 64.7224 - acc: 0.0653 - val_loss: 61.0679 - val_acc: 0.0469\n",
      "Epoch 94/100\n",
      "3063/3063 [==============================] - 0s 70us/step - loss: 64.5372 - acc: 0.0607 - val_loss: 61.1769 - val_acc: 0.0352\n",
      "Epoch 95/100\n",
      "3063/3063 [==============================] - 0s 72us/step - loss: 64.6952 - acc: 0.0597 - val_loss: 61.5532 - val_acc: 0.0352\n",
      "Epoch 96/100\n",
      "3063/3063 [==============================] - 0s 78us/step - loss: 64.7398 - acc: 0.0591 - val_loss: 61.2938 - val_acc: 0.0352\n",
      "Epoch 97/100\n",
      "3063/3063 [==============================] - 0s 81us/step - loss: 64.7291 - acc: 0.0542 - val_loss: 61.9503 - val_acc: 0.0616\n",
      "Epoch 98/100\n",
      "3063/3063 [==============================] - 0s 72us/step - loss: 65.2313 - acc: 0.0565 - val_loss: 61.8955 - val_acc: 0.0528\n",
      "Epoch 99/100\n",
      "3063/3063 [==============================] - 0s 128us/step - loss: 64.9368 - acc: 0.0548 - val_loss: 61.9834 - val_acc: 0.0469\n",
      "Epoch 100/100\n",
      "3063/3063 [==============================] - 1s 184us/step - loss: 64.3594 - acc: 0.0594 - val_loss: 61.7860 - val_acc: 0.0440\n",
      "341/341 [==============================] - 0s 91us/step\n",
      "test loss 61.78601440026963\n",
      "test accuracy 0.04398826979472141\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "Dense=keras.layers.Dense\n",
    "model.add(Dense(50, activation='relu', input_dim=X.shape[1]))\n",
    "keras.layers.Dropout(0.2)\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "keras.layers.Dropout(0.2)\n",
    "model.add(Dense(50, activation='relu'))\n",
    "keras.layers.Dropout(0.2)\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.summary()\n",
    "model.compile(loss='mean_squared_error',optimizer=Adam(lr=1e-3),metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,batch_size=20,epochs=100,verbose=1,validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test,y_test,verbose=1)\n",
    "          \n",
    "\n",
    "print('test loss',score[0])\n",
    "print('test accuracy',score[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train score: 0.003033\n",
      "X_test score: -0.002761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=10).fit(X_train, y_train)\n",
    "print(\"X_train score: {:.6f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"X_test score: {:.6f}\".format(ridge.score(X_test, y_test)))\n",
    "y_train_pred = ridge.predict(X_train)\n",
    "y_test_pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 train: 0.003, test: -0.003\n",
      "RMSE train: 8.039, test: 7.796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "        r2_score(y_train, y_train_pred),\n",
    "        r2_score(y_test, y_test_pred)))\n",
    "\n",
    "print('RMSE train: %.3f, test: %.3f' % (\n",
    "        np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.00\n",
      "Test set score: -0.00\n",
      "Number of features used: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>最低気温(℃)</td>\n",
       "      <td>0.037152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>降水量の合計(mm)</td>\n",
       "      <td>-0.020805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>最高気温(℃)</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     features  coefficient\n",
       "0     最低気温(℃)     0.037152\n",
       "1  降水量の合計(mm)    -0.020805\n",
       "2     最高気温(℃)     0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso05 = Lasso(alpha=0.5, max_iter=100000).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso05.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso05.score(X_test, y_test)))\n",
    "print(\"Number of features used: {}\".format(np.sum(lasso05.coef_ != 0)))\n",
    "\n",
    "significant = pd.DataFrame({\"features\":X.columns, \"coefficient\":lasso05.coef_})\n",
    "display(significant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
